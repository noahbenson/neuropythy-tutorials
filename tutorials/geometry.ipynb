{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Geometry"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This tutorial is an introduction to how Neuropythy manages the geometry of the human cortex. \n",
    "\n",
    "**Author**: &nbsp;&nbsp; [Noah C. Benson](mailto:nben@uw.edu)  \n",
    "**Date**: &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; June 11, 2022  \n",
    "**Link**: &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; [noahbenson/neuropythy-tutorials](https://github.com/noahbenson/neuropythy-tutorials)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To start with, we need to import various libraries. These include, first, neuropythy itself, and, second, the ipyvolume library for 3D plotting. We also import various utility libraries like os and sys."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import some standard/utility libraries:\n",
    "import os, sys, six # six provides python 2/3 compatibility\n",
    "\n",
    "# Import our numerical/scientific libraries, scipy and numpy:\n",
    "import numpy as np\n",
    "import scipy as sp\n",
    "\n",
    "# The neuropythy library is a swiss-army-knife for handling MRI data, especially\n",
    "# anatomical/structural data such as that produced by FreeSurfer or the HCP.\n",
    "# https://github.com/noahbenson/neuropythy\n",
    "import neuropythy as ny\n",
    "\n",
    "# Import graphics libraries:\n",
    "# Matplotlib/Pyplot is our 2D graphing library:\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# We also import ipyvolume, the 3D graphics library used by neurropythy, for 3D\n",
    "# surface rendering (optional).\n",
    "import ipyvolume as ipv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# These \"magic commands\" tell matplotlib that we want to plot figures inline and\n",
    "# That we are using qt as a backend; due to bugs in certain versions of\n",
    "# matplotlib, we put them in a separate cell from the import statements above\n",
    "# and the configuration statements below.\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Choose a Subject"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We need a subject whose ROIs we are going to draw. This notebook uses the subject `'bert'`, who is included in the docker-image that is part of the tutorials repository and with any FreeSurfer installation. You can optionally configure neuropythy to know where your FreeSurfer subjects directory is, allowing you to load subjects by their names alone (see [this page](https://github.com/noahbenson/neuropythy/wiki/Configuration) for information on configuring neuropythy), but the easiest way to ensure that you load the subject you intend to is to pass the subject's full path."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# If you aren't running the tutorial in the docker-image, make sure to set this\n",
    "# to a FreeSurfer subject directory that you have access to locally.\n",
    "sub = ny.freesurfer_subject('/data/freesurfer_subjects/bert')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mesh Objects"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Most of the geometric data of cortex is tracked by neuropythy using `Mesh` objects. These objects keep track of the various cortical surfaces (white, pial, midgray, inflated, etc.), which are represented by two pieces of data: (1) a matrix of vertex coordinates and (2) a matrix of triangle (face) indices.\n",
    "\n",
    "We'll start by looking at the coordinates of the white-matter surface."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Surfaces can be extracted by name using the surface method, or\n",
    "# they can be extracted from the surfaces dictionary (though\n",
    "# spherical surfaces such as the native sphere and the fsaverage\n",
    "# sphere are in the registrations dictionary instead of the surfaces\n",
    "# dictionary). Additionally, the white and pial surfaces can be \n",
    "# extracted using the white_surface and pial_surface aliases.\n",
    "mesh = sub.lh.surface('white')\n",
    "# or:\n",
    "# mesh = sub.lh.surfaces['white']\n",
    "# mesh = sub.lh.white_surface"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(133103, 133103, 133103, 133103)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Coordinate matrices are always 3 x N numpy matrices (where N is the\n",
    "# mesh's vertex count). If the mesh is a 2D matrix, this will be 2 x N\n",
    "# instead (see the plotting-2D.ipynb tutorial for more information\n",
    "# about making 2D flatmaps).\n",
    "(x,y,z) = mesh.coordinates\n",
    "\n",
    "# The shape of any of the x, y, and z coordinates should be the same\n",
    "# as the vertex count of the mesh itself.\n",
    "(len(x), len(y), len(z), mesh.vertex_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0ad88f96b5f64fc8a019ec5eb740d714",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Figure(camera=PerspectiveCamera(fov=45.0, position=(0.0, 0.0, 2.0), projectionMatrix=(1.0, 0.0,â€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# If we want to see what the point-cloud of vertices looks like, we can\n",
    "# use ipyvolume to make a scatter plot of these points. This is\n",
    "# typically hard to interpret, however, as point-clouds are not good\n",
    "# for seeing structure.\n",
    "# Note, also, that because ipyvolume, by default, doesn't force the axes\n",
    "# to represent space equally, this will look like a somewhat distorted\n",
    "# hemisphere.\n",
    "ipv.scatter(x, y, z, size=0.5)\n",
    "ipv.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The face matrix is the other critical part of the mesh. The faces are actually tracked by an object called a `Tesselation` that is part of both the mesh and the `Cortex` object that it came from (the `Cortex` and all of its `Mesh` surfaces share the same tesselation object)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Tesselation(<266202 faces>, <133103 vertices>)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sub.lh.tess"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The face matrix itself is a `3 x M` integer matrix that stores vertex labels. For most meshes, the vertex labels are equivalent to `range(N)` where `N` is the number of vertices; however, for sub-meshes such as flatmaps (see the `plotting-2D` tutorial), the label for each vertex remains the same as it was for its super-mesh. This essentially means that if `flatmap = supermesh.mask_flatmap(...)` (or similar) then `flatmap.labels` is the list of vertices from `supermesh` that were included in `flatmap`.\n",
    "\n",
    "The face matrix is stored in `tess.faces`; for flatmaps there is also `tess.indexed_faces` which uses vertex *indices* instead of vertex *labels*. So for a full surface mesh, `tess.indexed_faces` and `tess.faces` are equivalent, but for submeshes like flatmaps, `tess.indexed_faces` contains proper indices into the coordinate matrices or property vectors while `tess.faces` contains indices into the supermesh's coordinates or property vectors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(266202, 266202, 266202, 266202)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# An easy way to think about the face matrix is that each row corresponds to\n",
    "# one of the vertices at the corner of the face.\n",
    "(a,b,c) = sub.lh.tess.faces # or sub.lh.tess.indexed_faces\n",
    "\n",
    "# These should match the face count.\n",
    "(len(a), len(b), len(c), sub.lh.tess.face_count)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `Tesselation` object also stores the edges (and indexed edges) of the mesh. The edge matrix is similar to the face matrix, except that it is a `2 x Q` matrix where `Q` is the number of edges."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(399303, 399303, 399303)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(u, v) = sub.lh.tess.edges # or sub.lh.tess.indexed_edges\n",
    "(len(u), len(v), sub.lh.tess.edge_count)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Another useful piece of information tracked by the `Tesselation` object is `tess.neighborhoods` (and `tess.indexed_neighborhoods`). The `neighborhoods` value is a tuple with one element per vertex. Each element is the neighborhood of the associated vertex, which is a tuple of all the adjacent vertices in counter-clockwise order around the central vertex (counter-clockwise with respect to the vertex surface normal)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(133103, 133103)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nei = sub.lh.tess.neighborhoods\n",
    "\n",
    "(len(nei), sub.lh.vertex_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(96, 202, 210, 209, 99)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Pick a vertex and see what its neighbors are.\n",
    "vid = 100\n",
    "nei[100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 96,  99, 202, 209, 210])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Verify that these are the correct vertices using the edges or faces.\n",
    "(u,v) = sub.lh.tess.edges\n",
    "ii = (u == vid)\n",
    "jj = (v == vid)\n",
    "v_neis = np.concatenate([v[ii], u[jj]])\n",
    "np.unique(v_neis)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
